{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Email Exercise Ideas\n",
    "\n",
    "Since we can't really assess any code that would involve your personal email address, here are some ideas for you to test your new skills. Please keep in mind, we can not assess these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Ideas\n",
    "\n",
    "* Daily Automatic Email Reminder for your Tasks\n",
    "* Webscrape some statistics from a website automatically each day and email them to yourself\n",
    "* Automatically email daily/weekly/monthly reports at your work\n",
    "* Have end of day messages to your friends and family be sent out at random to spread joy\n",
    "* Be creative! Mix together any of the skills you've learned so far with email :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podcast Newsletter App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "IDEA:\n",
    "\n",
    "- create a Podcast newsletter for headlines from geopolitics, finance, science, tech, and AI.\n",
    "    - websites:\n",
    "        - geopolitics:\n",
    "            - https://www.reuters.com/world/\n",
    "            - https://ground.news/\n",
    "        - finance\n",
    "            - https://www.reuters.com/business/\n",
    "            - https://www.reuters.com/markets/ \n",
    "        - science:\n",
    "            - https://ground.news/interest/science\n",
    "            - https://www.sciencenews.org/\n",
    "        - tech: \n",
    "            - https://www.wired.com/\n",
    "            - https://ground.news/interest/tech\n",
    "        - AI:\n",
    "            - https://ground.news/interest/ai\n",
    "            - https://www.artificialintelligence-news.com/\n",
    "\n",
    "- newsletter that will be sent every second day at 9am (server needed?)\n",
    "- set up server on Google Cloud Run\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEPS:\n",
    "\n",
    "1. set up web scraper -> headlines, text\n",
    "2. set up LLM (perplexity) integration -> short explainers for biggest headlines (let it choose which is biggest headline)\n",
    "3. finalize text and add image as part of email\n",
    "4. set up emailing infrastructure\n",
    "5. integrate structure into Cloud Run\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add error handling\n",
    "\n",
    "import random\n",
    "import os\n",
    "import requests\n",
    "import bs4\n",
    "import smtplib\n",
    "import getpass\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - geopolitics:\n",
    "    # - https://www.reuters.com/world/\n",
    "    # - https://ground.news/\n",
    "# - finance\n",
    "    # - https://www.reuters.com/business/\n",
    "    # - https://www.reuters.com/markets/ \n",
    "# - science:\n",
    "    # - https://ground.news/interest/science\n",
    "    # - https://www.sciencenews.org/\n",
    "# - tech: \n",
    "    # - https://www.wired.com/\n",
    "    # - https://ground.news/interest/tech\n",
    "# - AI:\n",
    "    # - https://ground.news/interest/ai\n",
    "    # - https://www.artificialintelligence-news.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1 ### scrape headlines and first few lines\n",
    "\n",
    "# FIX needed?\n",
    "\n",
    "headlines_and_text = {} # dict for headlines and text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request websites\n",
    "\n",
    "# TODO use Forbes instead of reuters\n",
    "# reuters_geo = requests.get('https://www.reuters.com/world/')\n",
    "ground_geo = requests.get('https://ground.news/')\n",
    "# reuters_bus = requests.get('https://www.reuters.com/business/')\n",
    "# reuters_fin = requests.get('https://www.reuters.com/markets/')\n",
    "news_sci = requests.get('https://www.sciencenews.org/')\n",
    "ground_sci = requests.get('https://ground.news/interest/science')\n",
    "wired_tech = requests.get('https://www.wired.com/')\n",
    "ground_tech = requests.get('https://ground.news/interest/tech')\n",
    "ground_ai = requests.get('https://ground.news/interest/ai')\n",
    "news_ai = requests.get('https://www.artificialintelligence-news.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for getting headlines:\n",
    "# TODO add the images\n",
    "# TODO how to get rid of extra symbols in text?\n",
    "\n",
    "def get_headline(request, category, request_2=None):\n",
    "\n",
    "    def get_number_headlines(headlines, category):\n",
    "        mapping = {\n",
    "            \"geo\": 4,\n",
    "            \"science\" : 2,\n",
    "            \"tech\": 3,\n",
    "            \"ai\": 3\n",
    "        }\n",
    "\n",
    "        n = mapping[category]\n",
    "\n",
    "        return set(random.sample([headline.getText().strip() for headline in headlines], n))\n",
    "\n",
    "    if request_2 is None:\n",
    "        soup = bs4.BeautifulSoup(request.text, 'lxml')\n",
    "        headlines = soup.find_all('h4')\n",
    "\n",
    "        return list(get_number_headlines(headlines, category))\n",
    "    else:\n",
    "        soup_1 = bs4.BeautifulSoup(request.text, 'lxml')\n",
    "        headlines_1 = soup_1.find_all('h4')\n",
    "        headlines_1 = get_number_headlines(headlines_1, category)\n",
    "    \n",
    "        soup_2 = bs4.BeautifulSoup(request_2.text, 'lxml')\n",
    "        headlines_2 = soup_2.find_all('h4')\n",
    "        headlines_2 = get_number_headlines(headlines_2, category)\n",
    "        headlines_1.update(headlines_2)\n",
    "        return list(headlines_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Man Arrested in U.K. over Alleged Cyberattack that Affected European Airports',\n",
       " 'Drone disruption unlikely to hit profitability, Ryanair boss says',\n",
       " 'Denmarkâ€™s leader apologizes to Indigenous girls and women in Greenland for forced contraception',\n",
       " 'Stellantis To Pause Output At Six European Factories: Report']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting all headlines\n",
    "\n",
    "headlines_geo = get_headline(ground_geo, \"geo\")\n",
    "headlines_sci = get_headline(ground_sci, \"science\", news_sci)\n",
    "\n",
    "# todo finish all other websites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2 ### LLM integration (using QWEN)\n",
    "\n",
    "model_name = \"Qwen/Qwen3-4B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the model input\n",
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=32768\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
